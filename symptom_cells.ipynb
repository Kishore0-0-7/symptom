{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified Disease Prediction from Symptoms\n",
    "This notebook demonstrates disease prediction using machine learning based on patient symptoms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Deep learning libraries\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    tensorflow_available = True\n",
    "except ImportError:\n",
    "    print(\"TensorFlow not available. Deep learning model will be disabled.\")\n",
    "    tensorflow_available = False\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords and Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define English stopwords (simplified version)\n",
    "STOPWORDS = {\n",
    "    'a', 'an', 'the', 'and', 'but', 'or', 'if', 'because', 'as', 'until', 'while',\n",
    "    'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through',\n",
    "    'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in',\n",
    "    'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "    'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "    'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    "    'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'i',\n",
    "    'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "    'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "    'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "    'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "    'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "    'did', 'doing', 'would', 'could', 'should', 'ought', 'i\\'m', 'you\\'re', 'he\\'s',\n",
    "    'she\\'s', 'it\\'s', 'we\\'re', 'they\\'re', 'i\\'ve', 'you\\'ve', 'we\\'ve', 'they\\'ve',\n",
    "    'i\\'d', 'you\\'d', 'he\\'d', 'she\\'d', 'we\\'d', 'they\\'d', 'i\\'ll', 'you\\'ll', 'he\\'ll',\n",
    "    'she\\'ll', 'we\\'ll', 'they\\'ll', 'isn\\'t', 'aren\\'t', 'wasn\\'t', 'weren\\'t', 'hasn\\'t',\n",
    "    'haven\\'t', 'hadn\\'t', 'doesn\\'t', 'don\\'t', 'didn\\'t', 'won\\'t', 'wouldn\\'t',\n",
    "    'shan\\'t', 'shouldn\\'t', 'can\\'t', 'cannot', 'couldn\\'t', 'mustn\\'t', 'let\\'s',\n",
    "    'that\\'s', 'who\\'s', 'what\\'s', 'here\\'s', 'there\\'s', 'when\\'s', 'where\\'s', 'why\\'s',\n",
    "    'how\\'s'\n",
    "}\n",
    "\n",
    "# Simple text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Simplified text preprocessing without relying on NLTK\"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace punctuation with spaces\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    \n",
    "    # Tokenize by splitting on whitespace\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in STOPWORDS]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample dataset\n",
    "def create_sample_dataset():\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    \n",
    "    data = \"\"\"Symptoms,Disease\n",
    "fever headache cough,Common Cold\n",
    "high fever severe headache stiff neck light sensitivity,Meningitis\n",
    "chest pain shortness of breath sweating,Heart Attack\n",
    "fatigue weight loss night sweats cough,Tuberculosis\n",
    "abdominal pain diarrhea nausea vomiting,Gastroenteritis\n",
    "high fever fatigue sore throat swollen lymph glands,Mononucleosis\n",
    "fever rash joint pain muscle pain,Dengue\n",
    "frequent urination excessive thirst hunger weight loss,Diabetes\n",
    "wheezing shortness of breath chest tightness coughing,Asthma\n",
    "pain numbness tingling in hands feet,Peripheral Neuropathy\n",
    "dry mouth blurred vision frequent urination,Type 2 Diabetes\n",
    "headache nausea vomiting dizziness,Migraine\n",
    "severe joint pain swelling stiffness,Rheumatoid Arthritis\n",
    "fever headache fatigue muscle aches,Influenza\n",
    "sore throat difficulty swallowing fever,Strep Throat\n",
    "rash fever fatigue headache,Measles\n",
    "cough mucus shortness of breath wheezing,Bronchitis\n",
    "itchy eyes runny nose sneezing congestion,Allergic Rhinitis\n",
    "painful urination urgency frequency,Urinary Tract Infection\n",
    "abdominal pain bloating cramping diarrhea,Irritable Bowel Syndrome\n",
    "jaundice abdominal pain dark urine,Hepatitis\n",
    "fatigue muscle weakness numbness tingling,Multiple Sclerosis\n",
    "tremor stiffness slow movement,Parkinson's Disease\n",
    "recurring headaches seizures vision problems,Brain Tumor\n",
    "chest discomfort pain sweating nausea,Angina\n",
    "vision loss eye pain redness,Glaucoma\n",
    "trouble sleeping mood changes anxiety,Depression\n",
    "joint pain swelling warmth redness,Gout\n",
    "dizziness vertigo hearing loss tinnitus,Meniere's Disease\n",
    "lower back pain numbness tingling in legs,Herniated Disc\"\"\"\n",
    "    \n",
    "    with open('data/symptom_disease.csv', 'w') as f:\n",
    "        f.write(data)\n",
    "    \n",
    "    print(\"Sample dataset created at data/symptom_disease.csv\")\n",
    "\n",
    "# Load and process dataset\n",
    "def load_and_process_data():\n",
    "    # Check if the data file exists, if not create it\n",
    "    try:\n",
    "        df = pd.read_csv('data/symptom_disease.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Dataset not found, creating sample data...\")\n",
    "        create_sample_dataset()\n",
    "        df = pd.read_csv('data/symptom_disease.csv')\n",
    "    \n",
    "    print(\"Dataset Shape:\", df.shape)\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Process the symptoms with our simplified approach\n",
    "    df['Processed_Symptoms'] = df['Symptoms'].apply(preprocess_text)\n",
    "    print(\"\\nProcessed symptoms (first 5 rows):\")\n",
    "    print(df[['Symptoms', 'Processed_Symptoms']].head())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot disease distribution\n",
    "def plot_disease_distribution(df):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    df['Disease'].value_counts().plot(kind='bar')\n",
    "    plt.title('Disease Distribution')\n",
    "    plt.xlabel('Disease')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and split data\n",
    "def prepare_features(df):\n",
    "    # Create a label encoder for the disease classes\n",
    "    le = LabelEncoder()\n",
    "    df['Disease_Encoded'] = le.fit_transform(df['Disease'])\n",
    "    \n",
    "    # Split the data\n",
    "    X = df['Processed_Symptoms']\n",
    "    y = df['Disease_Encoded']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Convert text to TF-IDF vectors\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    print(f\"Training set size: {len(X_train)}\")\n",
    "    print(f\"Testing set size: {len(X_test)}\")\n",
    "    \n",
    "    return X_train_tfidf, X_test_tfidf, y_train, y_test, tfidf_vectorizer, le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train machine learning models\n",
    "def train_ml_models(X_train_tfidf, y_train, X_test_tfidf, y_test, le):\n",
    "    # Train Naive Bayes model\n",
    "    nb_model = MultinomialNB()\n",
    "    nb_model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "    accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "    print(f\"Naive Bayes Accuracy: {accuracy_nb:.4f}\")\n",
    "    \n",
    "    # Train Random Forest model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred_rf = rf_model.predict(X_test_tfidf)\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    print(f\"Random Forest Accuracy: {accuracy_rf:.4f}\")\n",
    "    \n",
    "    return nb_model, rf_model, accuracy_nb, accuracy_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train deep learning model (if TensorFlow is available)\n",
    "def train_deep_learning_model(X_train_tfidf, y_train, X_test_tfidf, y_test, le):\n",
    "    if not tensorflow_available:\n",
    "        print(\"TensorFlow not available - skipping deep learning model\")\n",
    "        return None, 0.0, X_train_tfidf.shape[1]\n",
    "    \n",
    "    # Prepare data for deep learning\n",
    "    X_train_dense = X_train_tfidf.toarray()\n",
    "    X_test_dense = X_test_tfidf.toarray()\n",
    "    \n",
    "    num_classes = len(le.classes_)\n",
    "    y_train_onehot = to_categorical(y_train, num_classes=num_classes)\n",
    "    y_test_onehot = to_categorical(y_test, num_classes=num_classes)\n",
    "    \n",
    "    # Build neural network\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_train_dense.shape[1],)),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train_dense, y_train_onehot,\n",
    "                        epochs=20,\n",
    "                        batch_size=8,\n",
    "                        validation_split=0.1,\n",
    "                        verbose=1)\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Evaluate\n",
    "    loss, accuracy_dl = model.evaluate(X_test_dense, y_test_onehot, verbose=0)\n",
    "    print(f\"Deep Learning Model Accuracy: {accuracy_dl:.4f}\")\n",
    "    \n",
    "    return model, accuracy_dl, X_train_dense.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance\n",
    "def compare_models(nb_accuracy, rf_accuracy, dl_accuracy):\n",
    "    models = ['Naive Bayes', 'Random Forest', 'Deep Learning']\n",
    "    accuracies = [nb_accuracy, rf_accuracy, dl_accuracy]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(models, accuracies, color=['blue', 'green', 'red'])\n",
    "    plt.title('Model Accuracy Comparison')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0, 1.0)\n",
    "    \n",
    "    for i, acc in enumerate(accuracies):\n",
    "        plt.text(i, acc + 0.01, f'{acc:.4f}', ha='center')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "def predict_disease(symptoms_text, tfidf_vectorizer, nb_model, rf_model, dl_model, le, model_type='rf'):\n",
    "    # Preprocess the input symptoms\n",
    "    processed_symptoms = preprocess_text(symptoms_text)\n",
    "    \n",
    "    # Vectorize the processed symptoms\n",
    "    symptoms_tfidf = tfidf_vectorizer.transform([processed_symptoms])\n",
    "    \n",
    "    # Make prediction based on the selected model\n",
    "    if model_type == 'nb':\n",
    "        prediction = nb_model.predict(symptoms_tfidf)\n",
    "        probabilities = nb_model.predict_proba(symptoms_tfidf)\n",
    "    elif model_type == 'rf':\n",
    "        prediction = rf_model.predict(symptoms_tfidf)\n",
    "        probabilities = rf_model.predict_proba(symptoms_tfidf)\n",
    "    elif model_type == 'dl' and tensorflow_available and dl_model is not None:\n",
    "        symptoms_dense = symptoms_tfidf.toarray()\n",
    "        probabilities = dl_model.predict(symptoms_dense)[0]\n",
    "        prediction = [np.argmax(probabilities)]\n",
    "    else:\n",
    "        if model_type == 'dl':\n",
    "            print(\"Deep learning model not available, using Random Forest instead\")\n",
    "        prediction = rf_model.predict(symptoms_tfidf)\n",
    "        probabilities = rf_model.predict_proba(symptoms_tfidf)\n",
    "        model_type = 'rf'\n",
    "    \n",
    "    # Get the predicted disease name\n",
    "    predicted_disease = le.inverse_transform(prediction)[0]\n",
    "    \n",
    "    # Get the top 3 predictions with probabilities\n",
    "    if model_type == 'dl':\n",
    "        top_indices = np.argsort(probabilities)[-3:][::-1]\n",
    "        top_probabilities = probabilities[top_indices]\n",
    "    else:\n",
    "        top_indices = np.argsort(probabilities[0])[-3:][::-1]\n",
    "        top_probabilities = probabilities[0][top_indices]\n",
    "    \n",
    "    top_diseases = le.inverse_transform(top_indices)\n",
    "    \n",
    "    return {\n",
    "        'predicted_disease': predicted_disease,\n",
    "        'top_diseases': list(zip(top_diseases, top_probabilities)),\n",
    "        'input_symptoms': symptoms_text,\n",
    "        'processed_symptoms': processed_symptoms\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction results\n",
    "def visualize_prediction(result):\n",
    "    diseases = [disease for disease, _ in result['top_diseases']]\n",
    "    probabilities = [prob*100 for _, prob in result['top_diseases']]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(range(len(diseases)), probabilities, color='skyblue')\n",
    "    plt.xlabel('Disease')\n",
    "    plt.ylabel('Probability (%)')\n",
    "    plt.title('Disease Prediction Results')\n",
    "    plt.xticks(range(len(diseases)), diseases, rotation=30)\n",
    "    plt.ylim(0, 100)\n",
    "    \n",
    "    for bar, prob in zip(bars, probabilities):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                 f'{prob:.2f}%', ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive prediction function\n",
    "def predict_from_input(tfidf_vectorizer, nb_model, rf_model, dl_model, le):\n",
    "    print(\"DISEASE PREDICTION SYSTEM\")\n",
    "    print(\"-\" * 25)\n",
    "    \n",
    "    symptoms = input(\"Enter symptoms (separated by spaces): \")\n",
    "    \n",
    "    print(\"\\nSelect model:\\n1. Naive Bayes\\n2. Random Forest\\n3. Deep Learning\")\n",
    "    choice = input(\"Enter choice (1-3): \")\n",
    "    \n",
    "    model_map = {'1': 'nb', '2': 'rf', '3': 'dl'}\n",
    "    model_type = model_map.get(choice, 'rf')  # Default to RF\n",
    "    \n",
    "    result = predict_disease(\n",
    "        symptoms, \n",
    "        tfidf_vectorizer, \n",
    "        nb_model, \n",
    "        rf_model, \n",
    "        dl_model, \n",
    "        le, \n",
    "        model_type\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nBased on symptoms: '{symptoms}'\")\n",
    "    print(f\"Processed symptoms: '{result['processed_symptoms']}'\")\n",
    "    print(f\"Predicted Disease: {result['predicted_disease']}\")\n",
    "    \n",
    "    print(\"\\nTop 3 Possible Diseases:\")\n",
    "    for disease, prob in result['top_diseases']:\n",
    "        print(f\"- {disease}: {prob*100:.2f}%\")\n",
    "    \n",
    "    visualize_prediction(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def main():\n",
    "    print(\"===== SIMPLIFIED DISEASE PREDICTION SYSTEM =====\")\n",
    "    print(\"This version uses simplified text processing to avoid NLTK issues.\")\n",
    "    \n",
    "    # Load and process the dataset\n",
    "    print(\"\\nLoading and processing data...\")\n",
    "    df = load_and_process_data()\n",
    "    \n",
    "    # Plot disease distribution\n",
    "    print(\"\\nPlotting disease distribution...\")\n",
    "    plot_disease_distribution(df)\n",
    "    \n",
    "    # Prepare features\n",
    "    print(\"\\nPreparing features...\")\n",
    "    X_train_tfidf, X_test_tfidf, y_train, y_test, tfidf_vectorizer, le = prepare_features(df)\n",
    "    \n",
    "    # Train machine learning models\n",
    "    print(\"\\nTraining machine learning models...\")\n",
    "    nb_model, rf_model, nb_accuracy, rf_accuracy = train_ml_models(\n",
    "        X_train_tfidf, y_train, X_test_tfidf, y_test, le\n",
    "    )\n",
    "    \n",
    "    # Train deep learning model\n",
    "    print(\"\\nTraining deep learning model...\")\n",
    "    dl_model, dl_accuracy, input_shape = train_deep_learning_model(\n",
    "        X_train_tfidf, y_train, X_test_tfidf, y_test, le\n",
    "    )\n",
    "    \n",
    "    # Compare models\n",
    "    print(\"\\nComparing model performance...\")\n",
    "    compare_models(nb_accuracy, rf_accuracy, dl_accuracy)\n",
    "    \n",
    "    # Start interactive prediction\n",
    "    print(\"\\nWould you like to make predictions? (y/n)\")\n",
    "    choice = input().lower()\n",
    "    \n",
    "    if choice == 'y':\n",
    "        while True:\n",
    "            predict_from_input(tfidf_vectorizer, nb_model, rf_model, dl_model, le)\n",
    "            \n",
    "            print(\"\\nTry another prediction? (y/n)\")\n",
    "            choice = input().lower()\n",
    "            if choice != 'y':\n",
    "                break\n",
    "    \n",
    "    print(\"\\nDisease Prediction demo completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
