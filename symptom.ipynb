{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Simplified Disease Prediction from Symptoms\n",
    "Interactive symptom analyzer for Jupyter Notebook with visible training process\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "# Suppress tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Import visualization libraries with fallbacks\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    # Set plot style\n",
    "    plt.style.use('ggplot')\n",
    "    sns.set(style='whitegrid')\n",
    "    visualization_available = True\n",
    "except ImportError:\n",
    "    print(\"Warning: Matplotlib or Seaborn not available. Visualizations will be disabled.\")\n",
    "    visualization_available = False\n",
    "\n",
    "# Optional imports for progress tracking\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    from IPython.display import display, clear_output\n",
    "    ipython_available = True\n",
    "except ImportError:\n",
    "    tqdm = lambda x, **kwargs: x  # Fallback for tqdm\n",
    "    ipython_available = False\n",
    "\n",
    "# ML libraries\n",
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    sklearn_available = True\n",
    "except ImportError:\n",
    "    print(\"Error: scikit-learn is required for this application.\")\n",
    "    sklearn_available = False\n",
    "\n",
    "# Deep learning libraries\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    tensorflow_available = True\n",
    "except ImportError:\n",
    "    print(\"TensorFlow not available. Deep learning model will be disabled.\")\n",
    "    tensorflow_available = False\n",
    "\n",
    "# Define English stopwords (simplified version)\n",
    "STOPWORDS = {\n",
    "    'a', 'an', 'the', 'and', 'but', 'or', 'if', 'because', 'as', 'until', 'while',\n",
    "    'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through',\n",
    "    'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in',\n",
    "    'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "    'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "    'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    "    'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'i',\n",
    "    'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "    'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "    'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "    'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "    'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "    'did', 'doing', 'would', 'could', 'should', 'ought', 'i\\'m', 'you\\'re', 'he\\'s',\n",
    "    'she\\'s', 'it\\'s', 'we\\'re', 'they\\'re', 'i\\'ve', 'you\\'ve', 'we\\'ve', 'they\\'ve',\n",
    "    'i\\'d', 'you\\'d', 'he\\'d', 'she\\'d', 'we\\'d', 'they\\'d', 'i\\'ll', 'you\\'ll', 'he\\'ll',\n",
    "    'she\\'ll', 'we\\'ll', 'they\\'ll', 'isn\\'t', 'aren\\'t', 'wasn\\'t', 'weren\\'t', 'hasn\\'t',\n",
    "    'haven\\'t', 'hadn\\'t', 'doesn\\'t', 'don\\'t', 'didn\\'t', 'won\\'t', 'wouldn\\'t',\n",
    "    'shan\\'t', 'shouldn\\'t', 'can\\'t', 'cannot', 'couldn\\'t', 'mustn\\'t', 'let\\'s',\n",
    "    'that\\'s', 'who\\'s', 'what\\'s', 'here\\'s', 'there\\'s', 'when\\'s', 'where\\'s', 'why\\'s',\n",
    "    'how\\'s'\n",
    "}\n",
    "\n",
    "# Simple text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Simplified text preprocessing without relying on NLTK\"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace punctuation with spaces\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    \n",
    "    # Tokenize by splitting on whitespace\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in STOPWORDS]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "def create_sample_dataset():\n",
    "    \"\"\"Create and display sample dataset with progress bar\"\"\"\n",
    "    print(\"Creating sample dataset...\")\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    \n",
    "    # Expanding dataset with multiple examples per disease to improve learning\n",
    "    data = \"\"\"Symptoms,Disease\n",
    "fever headache cough,Common Cold\n",
    "mild fever runny nose sore throat,Common Cold\n",
    "cough congestion sneezing,Common Cold\n",
    "headache sore throat mild fever,Common Cold\n",
    "fatigue cough runny nose,Common Cold\n",
    "high fever severe headache stiff neck light sensitivity,Meningitis\n",
    "stiff neck fever vomiting confusion,Meningitis\n",
    "headache fever stiff neck rash,Meningitis\n",
    "light sensitivity headache fever neck pain,Meningitis\n",
    "confusion fever stiff neck headache,Meningitis\n",
    "chest pain shortness of breath sweating,Heart Attack\n",
    "pain radiating to arm jaw neck,Heart Attack\n",
    "chest pressure nausea cold sweat,Heart Attack\n",
    "shortness of breath chest discomfort fatigue,Heart Attack\n",
    "chest tightness dizziness anxiety,Heart Attack\n",
    "fatigue weight loss night sweats cough,Tuberculosis\n",
    "coughing blood chest pain fever,Tuberculosis\n",
    "fatigue persistent cough weight loss,Tuberculosis\n",
    "night sweats fever persistent cough,Tuberculosis\n",
    "chest pain fatigue coughing blood,Tuberculosis\n",
    "abdominal pain diarrhea nausea vomiting,Gastroenteritis\n",
    "stomach cramps watery diarrhea,Gastroenteritis\n",
    "nausea vomiting fever diarrhea,Gastroenteritis\n",
    "abdominal pain fever vomiting,Gastroenteritis\n",
    "diarrhea dehydration stomach pain,Gastroenteritis\n",
    "high fever fatigue sore throat swollen lymph glands,Mononucleosis\n",
    "swollen lymph nodes fatigue fever,Mononucleosis\n",
    "extreme fatigue sore throat headache,Mononucleosis\n",
    "fever swollen spleen fatigue,Mononucleosis\n",
    "sore throat fever fatigue rash,Mononucleosis\n",
    "fever rash joint pain muscle pain,Dengue\n",
    "high fever headache pain behind eyes,Dengue\n",
    "muscle joint pain rash vomiting,Dengue\n",
    "fever rash fatigue bleeding gums,Dengue\n",
    "severe headache pain behind eyes fever,Dengue\n",
    "frequent urination excessive thirst hunger weight loss,Diabetes\n",
    "increased thirst frequent urination fatigue,Diabetes\n",
    "blurry vision slow healing wounds,Diabetes\n",
    "weight loss extreme hunger fatigue,Diabetes\n",
    "tingling hands feet excessive thirst,Diabetes\n",
    "wheezing shortness of breath chest tightness coughing,Asthma\n",
    "shortness of breath wheezing coughing,Asthma\n",
    "chest tightness difficulty breathing wheezing,Asthma\n",
    "coughing at night shortness of breath,Asthma\n",
    "exercise induced breathing difficulty,Asthma\"\"\"\n",
    "    \n",
    "    with open('data/symptom_disease.csv', 'w') as f:\n",
    "        f.write(data)\n",
    "    \n",
    "    print(\"âœ“ Sample dataset created successfully\")\n",
    "    return pd.read_csv('data/symptom_disease.csv')\n",
    "\n",
    "def visualize_dataset(df):\n",
    "    \"\"\"Display dataset statistics and visualizations\"\"\"\n",
    "    print(\"\\n=== Dataset Overview ===\")\n",
    "    print(f\"Total samples: {len(df)}\")\n",
    "    print(f\"Number of unique diseases: {df['Disease'].nunique()}\")\n",
    "    \n",
    "    # Add processed symptoms column if not exists\n",
    "    if 'Processed_Symptoms' not in df.columns:\n",
    "        df['Processed_Symptoms'] = df['Symptoms'].apply(preprocess_text)\n",
    "    \n",
    "    # Disease distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    disease_counts = df['Disease'].value_counts()\n",
    "    sns.barplot(x=disease_counts.values, y=disease_counts.index)\n",
    "    plt.title('Distribution of Diseases in Dataset')\n",
    "    plt.xlabel('Number of Samples')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Most common symptoms visualization\n",
    "    try:\n",
    "        from wordcloud import WordCloud\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(df['Symptoms']))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title('Common Symptoms Word Cloud')\n",
    "        plt.show()\n",
    "    except ImportError:\n",
    "        print(\"WordCloud package not available. Displaying top symptoms instead.\")\n",
    "        # Alternative visualization - count term frequency\n",
    "        all_symptoms = ' '.join(df['Symptoms']).split()\n",
    "        symptom_freq = {}\n",
    "        for symptom in all_symptoms:\n",
    "            if symptom not in STOPWORDS and len(symptom) > 2:\n",
    "                symptom_freq[symptom] = symptom_freq.get(symptom, 0) + 1\n",
    "        \n",
    "        # Sort symptoms by frequency\n",
    "        top_symptoms = sorted(symptom_freq.items(), key=lambda x: x[1], reverse=True)[:15]\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(x=[freq for _, freq in top_symptoms], y=[symptom for symptom, _ in top_symptoms])\n",
    "        plt.title('Most Common Symptoms in Dataset')\n",
    "        plt.xlabel('Frequency')\n",
    "        plt.ylabel('Symptom')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def train_models(show_progress=True):\n",
    "    \"\"\"Train models with visible progress and visualizations\"\"\"\n",
    "    if show_progress:\n",
    "        print(\"\\n=== Starting Model Training Process ===\")\n",
    "    \n",
    "    # Load and visualize data\n",
    "    df = create_sample_dataset()\n",
    "    if show_progress:\n",
    "        visualize_dataset(df)\n",
    "    \n",
    "    # Create label encoder\n",
    "    le = LabelEncoder()\n",
    "    df['Disease_Encoded'] = le.fit_transform(df['Disease'])\n",
    "    \n",
    "    # Split data\n",
    "    X = df['Processed_Symptoms']\n",
    "    y = df['Disease_Encoded']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    if show_progress:\n",
    "        print(\"\\n=== Feature Extraction ===\")\n",
    "        print(\"Converting text to TF-IDF features...\")\n",
    "    \n",
    "    # Vectorize text\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=100)\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    if show_progress:\n",
    "        print(f\"âœ“ Created {X_train_tfidf.shape[1]} features\")\n",
    "    \n",
    "    # Train Naive Bayes model\n",
    "    if show_progress:\n",
    "        print(\"\\n=== Training Naive Bayes Model ===\")\n",
    "    nb_model = MultinomialNB(alpha=0.5)\n",
    "    nb_model.fit(X_train_tfidf, y_train)\n",
    "    nb_pred = nb_model.predict(X_test_tfidf)\n",
    "    nb_acc = accuracy_score(y_test, nb_pred)\n",
    "    \n",
    "    if show_progress:\n",
    "        print(f\"âœ“ Naive Bayes Accuracy: {nb_acc:.2%}\")\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(confusion_matrix(y_test, nb_pred), annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Naive Bayes Confusion Matrix')\n",
    "        plt.show()\n",
    "    \n",
    "    # Train Random Forest model\n",
    "    if show_progress:\n",
    "        print(\"\\n=== Training Random Forest Model ===\")\n",
    "        print(\"Training with 50 trees...\")\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=50,\n",
    "        max_depth=5,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_train_tfidf, y_train)\n",
    "    rf_pred = rf_model.predict(X_test_tfidf)\n",
    "    rf_acc = accuracy_score(y_test, rf_pred)\n",
    "    \n",
    "    if show_progress:\n",
    "        print(f\"âœ“ Random Forest Accuracy: {rf_acc:.2%}\")\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(confusion_matrix(y_test, rf_pred), annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Random Forest Confusion Matrix')\n",
    "        plt.show()\n",
    "    \n",
    "    # Train Deep Learning model if available\n",
    "    if tensorflow_available:\n",
    "        if show_progress:\n",
    "            print(\"\\n=== Training Deep Learning Model ===\")\n",
    "            print(\"Building neural network...\")\n",
    "        \n",
    "        X_train_dense = X_train_tfidf.toarray()\n",
    "        X_test_dense = X_test_tfidf.toarray()\n",
    "        num_classes = len(le.classes_)\n",
    "        y_train_onehot = to_categorical(y_train, num_classes=num_classes)\n",
    "        \n",
    "        dl_model = Sequential([\n",
    "            Dense(32, activation='relu', input_shape=(X_train_dense.shape[1],)),\n",
    "            Dropout(0.3),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        dl_model.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        if show_progress:\n",
    "            print(\"Training for 30 epochs...\")\n",
    "            history = dl_model.fit(X_train_dense, y_train_onehot,\n",
    "                               epochs=30,\n",
    "                               batch_size=4,\n",
    "                               validation_split=0.2,\n",
    "                               verbose=1)\n",
    "            \n",
    "            # Plot training history\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(history.history['accuracy'], label='Training')\n",
    "            plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "            plt.title('Model Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(history.history['loss'], label='Training')\n",
    "            plt.plot(history.history['val_loss'], label='Validation')\n",
    "            plt.title('Model Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            dl_pred = np.argmax(dl_model.predict(X_test_dense), axis=1)\n",
    "            dl_acc = accuracy_score(y_test, dl_pred)\n",
    "            print(f\"âœ“ Deep Learning Accuracy: {dl_acc:.2%}\")\n",
    "            \n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(confusion_matrix(y_test, dl_pred), annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title('Deep Learning Confusion Matrix')\n",
    "            plt.show()\n",
    "    else:\n",
    "        dl_model = None\n",
    "    \n",
    "    if show_progress:\n",
    "        print(\"\\n=== Model Comparison ===\")\n",
    "        models = ['Naive Bayes', 'Random Forest']\n",
    "        accuracies = [nb_acc, rf_acc]\n",
    "        if tensorflow_available:\n",
    "            models.append('Deep Learning')\n",
    "            accuracies.append(dl_acc)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(models, accuracies)\n",
    "        plt.title('Model Accuracies Comparison')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.ylim(0, 1)\n",
    "        for i, acc in enumerate(accuracies):\n",
    "            plt.text(i, acc + 0.01, f'{acc:.2%}', ha='center')\n",
    "        plt.show()\n",
    "    \n",
    "    return tfidf_vectorizer, nb_model, rf_model, dl_model, le\n",
    "\n",
    "def analyze_symptoms(symptoms_text, model_type='rf', show_training=True):\n",
    "    \"\"\"\n",
    "    Analyze symptoms with visible training process\n",
    "    \n",
    "    Parameters:\n",
    "    symptoms_text (str): Symptoms described by the user\n",
    "    model_type (str): Model to use for prediction ('nb', 'rf', or 'dl')\n",
    "    show_training (bool): Whether to show the training process visualization\n",
    "    \n",
    "    Returns:\n",
    "    dict: Analysis results\n",
    "    \"\"\"\n",
    "    # Train models if not already available\n",
    "    if 'GLOBAL_VECTORIZER' not in globals():\n",
    "        print(\"Training models for the first time...\")\n",
    "        global GLOBAL_VECTORIZER, GLOBAL_NB_MODEL, GLOBAL_RF_MODEL, GLOBAL_DL_MODEL, GLOBAL_LABEL_ENCODER\n",
    "        GLOBAL_VECTORIZER, GLOBAL_NB_MODEL, GLOBAL_RF_MODEL, GLOBAL_DL_MODEL, GLOBAL_LABEL_ENCODER = train_models(show_progress=show_training)\n",
    "    \n",
    "    # Use global models\n",
    "    tfidf_vectorizer = GLOBAL_VECTORIZER\n",
    "    nb_model = GLOBAL_NB_MODEL\n",
    "    rf_model = GLOBAL_RF_MODEL\n",
    "    dl_model = GLOBAL_DL_MODEL\n",
    "    le = GLOBAL_LABEL_ENCODER\n",
    "    \n",
    "    # Preprocess the input symptoms\n",
    "    processed_symptoms = preprocess_text(symptoms_text)\n",
    "    \n",
    "    if show_training:\n",
    "        print(f\"\\n=== Prediction Process ===\")\n",
    "        print(f\"Input symptoms: {symptoms_text}\")\n",
    "        print(f\"Processed symptoms: {processed_symptoms}\")\n",
    "    \n",
    "    # Vectorize the processed symptoms\n",
    "    symptoms_tfidf = tfidf_vectorizer.transform([processed_symptoms])\n",
    "    \n",
    "    if show_training:\n",
    "        # Show the vectorization results\n",
    "        feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "        feature_values = symptoms_tfidf.toarray()[0]\n",
    "        nonzero_features = [(feature_names[i], feature_values[i]) for i in range(len(feature_names)) if feature_values[i] > 0]\n",
    "        nonzero_features.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(\"\\nExtracted features:\")\n",
    "        for feature, value in nonzero_features[:10]:  # Show top 10 features\n",
    "            print(f\"  - {feature}: {value:.4f}\")\n",
    "    \n",
    "    # Make prediction based on the selected model\n",
    "    if model_type == 'nb':\n",
    "        if show_training:\n",
    "            print(\"\\nUsing Naive Bayes model for prediction...\")\n",
    "        prediction = nb_model.predict(symptoms_tfidf)\n",
    "        probabilities = nb_model.predict_proba(symptoms_tfidf)\n",
    "        model_name = \"Naive Bayes\"\n",
    "    elif model_type == 'rf':\n",
    "        if show_training:\n",
    "            print(\"\\nUsing Random Forest model for prediction...\")\n",
    "        prediction = rf_model.predict(symptoms_tfidf)\n",
    "        probabilities = rf_model.predict_proba(symptoms_tfidf)\n",
    "        model_name = \"Random Forest\"\n",
    "    elif model_type == 'dl' and tensorflow_available and dl_model is not None:\n",
    "        if show_training:\n",
    "            print(\"\\nUsing Deep Learning model for prediction...\")\n",
    "        symptoms_dense = symptoms_tfidf.toarray()\n",
    "        probabilities = dl_model.predict(symptoms_dense)[0]\n",
    "        prediction = [np.argmax(probabilities)]\n",
    "        model_name = \"Deep Learning\"\n",
    "    else:\n",
    "        if model_type == 'dl':\n",
    "            print(\"Deep learning model not available, using Random Forest instead\")\n",
    "        prediction = rf_model.predict(symptoms_tfidf)\n",
    "        probabilities = rf_model.predict_proba(symptoms_tfidf)\n",
    "        model_type = 'rf'\n",
    "        model_name = \"Random Forest\"\n",
    "    \n",
    "    # Get the predicted disease name\n",
    "    predicted_disease = le.inverse_transform(prediction)[0]\n",
    "    \n",
    "    # Get the top 3 predictions with probabilities\n",
    "    if model_type == 'dl':\n",
    "        top_indices = np.argsort(probabilities)[-3:][::-1]\n",
    "        top_probabilities = probabilities[top_indices]\n",
    "    else:\n",
    "        top_indices = np.argsort(probabilities[0])[-3:][::-1]\n",
    "        top_probabilities = probabilities[0][top_indices]\n",
    "    \n",
    "    top_diseases = le.inverse_transform(top_indices)\n",
    "    \n",
    "    # Create and display symptom analysis\n",
    "    print(\"\\n===== SYMPTOM ANALYSIS RESULTS =====\")\n",
    "    print(f\"Input symptoms: {symptoms_text}\")\n",
    "    if show_training:\n",
    "        print(f\"Processed symptoms: {processed_symptoms}\")\n",
    "    print(f\"Model used: {model_name}\")\n",
    "    \n",
    "    print(\"\\nPredicted Disease: \" + predicted_disease)\n",
    "    \n",
    "    print(\"\\nTop 3 Possible Diseases:\")\n",
    "    for disease, prob in zip(top_diseases, top_probabilities):\n",
    "        percentage = prob * 100\n",
    "        confidence = \"High\" if percentage > 75 else \"Medium\" if percentage > 50 else \"Low\"\n",
    "        print(f\"- {disease}: {percentage:.2f}% ({confidence} confidence)\")\n",
    "    \n",
    "    # Visualize the results\n",
    "    if visualization_available:\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            colors = ['#3498db', '#95a5a6', '#95a5a6']  # First one highlighted\n",
    "            bars = plt.bar(range(len(top_diseases)), [p*100 for p in top_probabilities], color=colors)\n",
    "            plt.xlabel('Disease')\n",
    "            plt.ylabel('Probability (%)')\n",
    "            plt.title('Disease Prediction Results')\n",
    "            plt.xticks(range(len(top_diseases)), top_diseases, rotation=30)\n",
    "            plt.ylim(0, 100)\n",
    "            \n",
    "            for bar, disease, prob in zip(bars, top_diseases, top_probabilities):\n",
    "                height = bar.get_height()\n",
    "                plt.text(bar.get_x() + bar.get_width()/2, height + 1, \n",
    "                         f'{prob*100:.1f}%', ha='center')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Could not create visualization: {e}\")\n",
    "    \n",
    "    # Offer additional information if needed\n",
    "    print(\"\\nTo try a different prediction model, call this function with model_type='nb', 'rf', or 'dl'\")\n",
    "    print(\"Example: analyze_symptoms('fever headache cough', model_type='nb')\")\n",
    "    \n",
    "    return {\n",
    "        'predicted_disease': predicted_disease,\n",
    "        'top_diseases': list(zip(top_diseases, top_probabilities)),\n",
    "        'input_symptoms': symptoms_text,\n",
    "        'processed_symptoms': processed_symptoms,\n",
    "        'model_used': model_name\n",
    "    }\n",
    "\n",
    "# Example usage for Jupyter Notebook\n",
    "def notebook_example():\n",
    "    \"\"\"\n",
    "    Interactive example for Jupyter Notebook showing the complete analysis process\n",
    "    \"\"\"\n",
    "    print(\"===== INTERACTIVE SYMPTOM ANALYZER DEMONSTRATION =====\")\n",
    "    print(\"This notebook demonstrates the disease prediction system with visible training process.\")\n",
    "    print(\"First, let's train our models with detailed visualization...\")\n",
    "    \n",
    "    # Initialize models globally for reuse\n",
    "    global GLOBAL_VECTORIZER, GLOBAL_NB_MODEL, GLOBAL_RF_MODEL, GLOBAL_DL_MODEL, GLOBAL_LABEL_ENCODER\n",
    "    GLOBAL_VECTORIZER, GLOBAL_NB_MODEL, GLOBAL_RF_MODEL, GLOBAL_DL_MODEL, GLOBAL_LABEL_ENCODER = train_models(show_progress=True)\n",
    "    \n",
    "    print(\"\\n\\n===== MODEL TRAINING COMPLETE =====\")\n",
    "    print(\"Now let's use our trained models to analyze some example symptoms.\")\n",
    "    \n",
    "    # Example 1: Simple cold symptoms\n",
    "    print(\"\\n===== EXAMPLE 1: COMMON COLD SYMPTOMS =====\")\n",
    "    symptoms = \"fever headache cough runny nose\"\n",
    "    print(f\"Analyzing symptoms: {symptoms}\")\n",
    "    analyze_symptoms(symptoms, model_type='rf', show_training=True)\n",
    "    \n",
    "    # Example 2: Heart attack symptoms with different model\n",
    "    print(\"\\n===== EXAMPLE 2: HEART ATTACK SYMPTOMS WITH NAIVE BAYES =====\")\n",
    "    symptoms = \"chest pain shortness of breath pain in arm sweating\"\n",
    "    print(f\"Analyzing symptoms: {symptoms}\")\n",
    "    analyze_symptoms(symptoms, model_type='nb', show_training=True)\n",
    "    \n",
    "    # Example 3: Unusual or mixed symptoms\n",
    "    print(\"\\n===== EXAMPLE 3: MIXED SYMPTOMS =====\")\n",
    "    symptoms = \"fatigue fever cough chest pain\"\n",
    "    print(f\"Analyzing symptoms: {symptoms}\")\n",
    "    analyze_symptoms(symptoms, model_type='rf', show_training=True)\n",
    "    \n",
    "    # Example 4: Deep learning model if available\n",
    "    if tensorflow_available and GLOBAL_DL_MODEL is not None:\n",
    "        print(\"\\n===== EXAMPLE 4: USING DEEP LEARNING MODEL =====\")\n",
    "        symptoms = \"stiff neck fever headache light sensitivity\"\n",
    "        print(f\"Analyzing symptoms: {symptoms}\")\n",
    "        analyze_symptoms(symptoms, model_type='dl', show_training=True)\n",
    "    \n",
    "    print(\"\\n===== INTERACTIVE USAGE =====\")\n",
    "    print(\"You can now use analyze_symptoms() with your own symptoms!\")\n",
    "    print(\"analyze_symptoms(symptoms_text, model_type='rf', show_training=True)\")\n",
    "    print(\"\\nWhere:\")\n",
    "    print(\"  - symptoms_text: Your symptoms as text (e.g. 'fever headache cough')\")\n",
    "    print(\"  - model_type: 'nb' (Naive Bayes), 'rf' (Random Forest), or 'dl' (Deep Learning)\")\n",
    "    print(\"  - show_training: True to see detailed analysis process, False for results only\")\n",
    "    \n",
    "    # Provide an input cell example for Jupyter\n",
    "    if ipython_available:\n",
    "        try:\n",
    "            from IPython.display import Markdown, display\n",
    "            display(Markdown(\"\"\"\n",
    "            ## Try it yourself!\n",
    "            \n",
    "            ```python\n",
    "            # Enter your symptoms below and run this cell\n",
    "            symptoms = \"enter your symptoms here\"\n",
    "            analyze_symptoms(symptoms, model_type='rf', show_training=True)\n",
    "            ```\n",
    "            \"\"\"))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def interactive_mode():\n",
    "    \"\"\"Get user input directly and provide analysis\"\"\"\n",
    "    print(\"===== INTERACTIVE SYMPTOM ANALYZER =====\")\n",
    "    print(\"This program helps predict possible diseases based on your symptoms.\")\n",
    "    print(\"First, we need to train our models...\")\n",
    "    \n",
    "    # Train models\n",
    "    global GLOBAL_VECTORIZER, GLOBAL_NB_MODEL, GLOBAL_RF_MODEL, GLOBAL_DL_MODEL, GLOBAL_LABEL_ENCODER\n",
    "    GLOBAL_VECTORIZER, GLOBAL_NB_MODEL, GLOBAL_RF_MODEL, GLOBAL_DL_MODEL, GLOBAL_LABEL_ENCODER = train_models(show_progress=True)\n",
    "    \n",
    "    print(\"\\n=== Training complete! ===\")\n",
    "    \n",
    "    while True:\n",
    "        # Get user input\n",
    "        print(\"\\nEnter your symptoms (separated by spaces) or 'exit' to quit:\")\n",
    "        symptoms = input(\"> \")\n",
    "        \n",
    "        if symptoms.lower() in ['exit', 'quit']:\n",
    "            print(\"\\nThank you for using the Symptom Analyzer!\")\n",
    "            break\n",
    "            \n",
    "        # Ask for model preference\n",
    "        print(\"\\nChoose a model for prediction:\")\n",
    "        print(\"1. Random Forest (recommended)\")\n",
    "        print(\"2. Naive Bayes\")\n",
    "        if tensorflow_available:\n",
    "            print(\"3. Deep Learning\")\n",
    "        \n",
    "        model_choice = input(\"Enter your choice (1-3) or press Enter for default: \")\n",
    "        \n",
    "        # Set model type based on user input\n",
    "        if model_choice == '2':\n",
    "            model_type = 'nb'\n",
    "        elif model_choice == '3' and tensorflow_available:\n",
    "            model_type = 'dl'\n",
    "        else:\n",
    "            model_type = 'rf'  # Default\n",
    "            \n",
    "        # Make prediction\n",
    "        analyze_symptoms(symptoms, model_type=model_type, show_training=True)\n",
    "        \n",
    "        print(\"\\n----------------------------------------\")\n",
    "\n",
    "# For Jupyter Notebook - just show usage info\n",
    "print(\"===== SYMPTOM ANALYZER FOR DISEASE PREDICTION =====\")\n",
    "\n",
    "# Check if running in Jupyter notebook\n",
    "in_notebook = False\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "    if get_ipython() is not None and 'IPKernelApp' in get_ipython().config:\n",
    "        in_notebook = True\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "if in_notebook:\n",
    "    print(\"Running in Jupyter Notebook environment\")\n",
    "    print(\"Use notebook_example() to see a demonstration with visible training process\")\n",
    "    print(\"Or use analyze_symptoms() directly with your own symptoms\")\n",
    "    print(\"Example: analyze_symptoms('fever headache cough', show_training=True)\")\n",
    "else:\n",
    "    # Direct script execution\n",
    "    interactive_mode()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
